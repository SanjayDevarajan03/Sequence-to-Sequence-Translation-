{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs5yLGWSnDDg",
        "outputId": "f57ca18e-3ea8-482a-9302-50528869bd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate spacy\n",
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "import datasets\n",
        "import tqdm\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "n8vSxCf9nRC7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1234\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "QJ7iippUoBaB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "rtjeRCohOkax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"bentrevett/multi30k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "30e87f71e7f3461899c89c3bbe7bf7a1",
            "9b22bf161ae14b61b736d148be2fb968",
            "c90404d4763b455ab1e5dcf6c9488716",
            "24264f4d34614801a9e58299cff86674",
            "ac19d0f0a72048c8aa39d81ce94c716e",
            "6ef753344c994424bbd7a61c69373b73",
            "997dc985d1414b9ea77e879e31c03751",
            "949f2debd5e043938bec92c4a7359bdd",
            "4262946908254a91b0f394dd62d578c8",
            "e0faddbfde0145c5b0b5c6de1243b0fc",
            "2b53100e23db4f7e9410fe0a952afd94",
            "fa85570d108c49469b2be8c0e9f61ce7",
            "1b774885c9ea4ab399ab99d80ce5c5a1",
            "c363218613a44d4e8053172907329778",
            "a2ee6a3c95684a4c9014b021e4ab86d6",
            "859b72b5f9f045b0af82b0adff4cf30d",
            "0544ca86bde34a1ea277d7aeb14ac869",
            "dfec2ec584714f91a9c0633747b7fc26",
            "cd8d152a8f43471eb3a355730d1660b6",
            "aafa4f8317dc42f19cdba7ffff650ba2",
            "37fccd0639a84e6785c8ffce95390563",
            "e161f4dd0aaa4a50b54efd529b82e6af",
            "198dcd8ebd644973861d940dfe33d88d",
            "93db0431f4164a8584c4f7f736808bb6",
            "2eaa56e963d442e18a01be99161442f6",
            "08087afbc5f94e27b7b8dea84cb186d1",
            "5809d7f73bce4d468fc1c98ab6d89eae",
            "fe3ad06514e74e3ab9e9701981312c9e",
            "91f66fc2e625409d820525ba4a2a7641",
            "ba45d039b4f743c0b68a898ff94a36d7",
            "aba78f5d457d466e9e8a90d916152815",
            "4453fcb4430b40c691e937a739f0c03d",
            "33fe9caec0d04d67ac93f31d99cb6e25",
            "e1e228dbe77e4cdf924b34822a98ba05",
            "0eeb1354cbdc4971a4331aa3f8a0cd15",
            "3ebb61c4eb4a4333b69741edcced509c",
            "4e258ab0237542d9bfbf7b9f408f83c9",
            "719692e0e67f451c8c9cca3b0965c877",
            "448b9e0ff0a4456186c318bff9383d73",
            "6d007170a702468b81caab1d0de86d26",
            "32bba85d33b049b2bc0aefc8bdac8add",
            "750b0c5088674f859c7d7f6d4bf72474",
            "45ba9d14e88a49d69a8449fdffccfed0",
            "e9d2a891a4444abfbc9a6facea488aae",
            "78c2528905b04e8abe301fb1ade6bf8f",
            "f83eaba812ed416eb8788e48245f5b52",
            "c618edbc7fd2406ab9e0bbf8c4673c92",
            "cf4f76624716430099b01f0b54796fc3",
            "004ac4d5daf34f76928fa10af7fac4fa",
            "94360c0666894419b21aee9fba2e52f7",
            "5b86bfe062054444bd5f666f65d3a366",
            "2567312739a94abab48e7908f46341ed",
            "64017dc9b9de4f5ba68d7e6db8c7576c",
            "48bf2b3764224e35b5ca614d6f3145af",
            "28086896ea5b42509f507ce3a25844bf",
            "36c103c395b9417fbf6208d626fb3956",
            "53ad15512ed84cbab61f0d999ff17eb9",
            "4fdac7f9130946888bdd5392ae6b52b5",
            "e1b36abdf7ad443dab4d708d76c930bf",
            "a0889c0cb1174f4483715f017ba56dca",
            "7cb3b7eb753e4eac80142519914b8b26",
            "dbb87674b1e0402d959499b39140feb3",
            "d8f6e6c268b04c11aefdf53f445d1358",
            "7fe3f8256284473b901b8adb00316c1b",
            "e8317133204d4d7389d717a2119b5ebe",
            "3178f85a5bf2455292d05ede2315b278",
            "55c54885a0ec4a129910fc2e22c31591",
            "9938fbe6a6794119893664734beac0d3",
            "be5e0b805b1c49ebb3ff5751fdf95ec5",
            "bc9038ecffb845f397d083586775bc1d",
            "1c350a86c4e145bca8c867f186f3ab68",
            "5c948dbe6a0447219b2ccc84007759c6",
            "ec21327fe3b14ee4b84d85e5ac5f7aa1",
            "1baab85695dd49658a5e8bbdc8b1d061",
            "712205250d78429a9bfc5771f96e8fd3",
            "c279a3792c6146a19b7d3aaa5dfb38f3",
            "dec164f831194dbeac2bd72171e415b7"
          ]
        },
        "id": "TJ8IGXPyodux",
        "outputId": "e2111f43-43bc-4b75-b939-bc3e376b9ec7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30e87f71e7f3461899c89c3bbe7bf7a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/4.60M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa85570d108c49469b2be8c0e9f61ce7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "val.jsonl:   0%|          | 0.00/164k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "198dcd8ebd644973861d940dfe33d88d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/156k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1e228dbe77e4cdf924b34822a98ba05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/29000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78c2528905b04e8abe301fb1ade6bf8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36c103c395b9417fbf6208d626fb3956"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c54885a0ec4a129910fc2e22c31591"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJY_vZItoj3P",
        "outputId": "91b0196b-70cc-47a8-f154-d8454c0a9471"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['en', 'de'],\n",
              "        num_rows: 29000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['en', 'de'],\n",
              "        num_rows: 1014\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['en', 'de'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a variable for each split"
      ],
      "metadata": {
        "id": "X_AOsB29OoYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = (\n",
        "    dataset[\"train\"],\n",
        "    dataset[\"validation\"],\n",
        "    dataset[\"test\"]\n",
        ")"
      ],
      "metadata": {
        "id": "sOv1KS5uolhO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0IP2_Tosbq",
        "outputId": "5e0cd68c-aea9-40e2-c6d8-ea4fe4463fa9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge wei\u00dfe M\u00e4nner sind im Freien in der N\u00e4he vieler B\u00fcsche.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the data"
      ],
      "metadata": {
        "id": "4HnBpapHOual"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "LgJ0caQ3otSZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_example(example, de_nlp, en_nlp, max_length, lower, sos_token, eos_token):\n",
        "  de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
        "  en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
        "  if lower:\n",
        "    de_tokens = [token.lower() for token in de_tokens]\n",
        "    en_tokens = [token.lower() for token in en_tokens]\n",
        "  en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "  de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "  return {\"de_tokens\":de_tokens, \"en_tokens\": en_tokens}"
      ],
      "metadata": {
        "id": "wS2WBVFXo93n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 1000\n",
        "lower = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "fn_kwargs = {\n",
        "    \"en_nlp\": en_nlp,\n",
        "    \"de_nlp\": de_nlp,\n",
        "    \"max_length\": max_length,\n",
        "    \"lower\": lower,\n",
        "    \"sos_token\": sos_token,\n",
        "    \"eos_token\": eos_token\n",
        "}\n",
        "\n",
        "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
        "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bf44060b3e7040dfb176fe0b52b128a9",
            "d50048daa89c433c8ae75a9bc4f69976",
            "9fc33759223048c785fb1e04f44ef267",
            "aef09f6d8cc44dcc80596c0a14233374",
            "a6c1387ed9d549a2bdb7af7871a3d9bd",
            "1b2c3e31b29f4c0e8844f5e2c4ca34de",
            "21cbdb3e9d044a5aa13e8e198d317998",
            "33c4ab81dcb144ca9df355900f87423a",
            "9d97286eafd44f22bf6c3a31301a86e1",
            "2bfde8b7bf4a470a862dfb2ec5fb360e",
            "1396c7b4da3542fa9c1abd0c89b0284c",
            "e49c692e945849debbcad683fea93b47",
            "bb45765174fe47b9bca8999fa0a4537b",
            "59f38a48e9f4452f9153373f8ad8330c",
            "1d51cd9facba40779001e5726266fa84",
            "d72273a87ac04714b7795723125897ed",
            "d0dd763164224bd48476dd78b6637c95",
            "23f71a8bf4cd480a9d68d0d4c658d335",
            "0b146b8abd764a7c86789b9582eda2d7",
            "f4ed1d4b0e25482b94845379ad80bed4",
            "238a5d96ce0f48d4a32f337fe44a68fe",
            "0bfcf9cbe9e0400aad92c57af107c406",
            "e21846a5e1a5423285851ada9442e121",
            "f61d85c3a53d44d4bf79843b9dd1f339",
            "661f96c83df746e39e9a9336f549be7b",
            "e00964a08d5e4e918d3894a44f5390a7",
            "65fd8a1d1d214f1fae56e05445f4ec71",
            "51f59f2b85664725b91f76a742d7fae9",
            "673ad880d91f4a6db50bccd16dc731fe",
            "dca795e29b4e42b3a2d2a5ce5788f898",
            "b341546524f54131b0707b53ce8ba7e5",
            "95a91418a26242c09f1837c71169c81c",
            "f7530d0c4524459a849c8f30d1b428ec"
          ]
        },
        "id": "RlzZ7E35pz0f",
        "outputId": "4822353f-1825-49ab-b2f5-a039c0bffd3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf44060b3e7040dfb176fe0b52b128a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e49c692e945849debbcad683fea93b47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e21846a5e1a5423285851ada9442e121"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "7F1bzkqcqfS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6eef1a0-79a0-4fec-e38e-0c2db2cc02d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge wei\u00dfe M\u00e4nner sind im Freien in der N\u00e4he vieler B\u00fcsche.',\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'wei\u00dfe',\n",
              "  'm\u00e4nner',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'n\u00e4he',\n",
              "  'vieler',\n",
              "  'b\u00fcsche',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_vocab(token_lists, min_freq, specials):\n",
        "  counter = Counter()\n",
        "  for token in token_lists:\n",
        "    counter.update(token)\n",
        "\n",
        "  # Here specials refer to the special tokens- <sos>, <eos>, <unk>, <pad>.\n",
        "  vocab = {token:idx for idx, token in enumerate(specials)}\n",
        "  idx = len(vocab)\n",
        "\n",
        "  for token, freq in counter.items():\n",
        "    if freq >= min_freq and token not in vocab:\n",
        "      vocab[token] = idx\n",
        "      idx += 1\n",
        "\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "zTgdapYwsUk7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "  def __init__(self, token_to_idx, unk_token=\"<unk>\"):\n",
        "    self.token_to_idx = token_to_idx\n",
        "    self.idx_to_token = {idx: token for token, idx in token_to_idx.items()}\n",
        "    self.unk_token = unk_token\n",
        "\n",
        "  def __getitem__(self, token):\n",
        "    return self.token_to_idx.get(token, self.token_to_idx[self.unk_token])\n",
        "\n",
        "  def lookup_token(self, indices):\n",
        "    return self.idx_to_token.get(indices, self.unk_token)\n",
        "\n",
        "  def lookup_tokens(self, indices):\n",
        "    return [self.lookup_token(index) for index in indices]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_to_idx)\n",
        "\n",
        "  def get_itos(self):\n",
        "    return [self.idx_to_token[i] for i in range(len(self.idx_to_token))]\n",
        "\n",
        "  def get_stoi(self):\n",
        "    return self.token_to_idx\n",
        "\n",
        "  def lookup_indices(self, tokens):\n",
        "    return [self[token] for token in tokens]"
      ],
      "metadata": {
        "id": "3TBvCvTnuiku"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_freq = 2\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [\n",
        "    unk_token,\n",
        "    pad_token,\n",
        "    sos_token,\n",
        "    eos_token\n",
        "]\n",
        "\n",
        "en_vocab = build_vocab(train_data[\"en_tokens\"], min_freq, special_tokens)\n",
        "de_vocab = build_vocab(train_data[\"de_tokens\"], min_freq, special_tokens)"
      ],
      "metadata": {
        "id": "klWmZnFGtLMw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj = Vocab(en_vocab, unk_token)\n",
        "en_vocab_obj.get_itos()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhb44aq4vknO",
        "outputId": "431a3d1e-0f92-4450-d7c6-9129a1ca3e5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<sos>',\n",
              " '<eos>',\n",
              " 'two',\n",
              " 'young',\n",
              " ',',\n",
              " 'white',\n",
              " 'males',\n",
              " 'are']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "de_vocab_obj = Vocab(de_vocab, unk_token)\n",
        "de_vocab_obj.get_itos()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gm1-oRuv2Kq",
        "outputId": "50ea51cb-61f9-4a02-fb13-53ce214bb3f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<sos>',\n",
              " '<eos>',\n",
              " 'zwei',\n",
              " 'junge',\n",
              " 'wei\u00dfe',\n",
              " 'm\u00e4nner',\n",
              " 'sind',\n",
              " 'im']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the text from the index"
      ],
      "metadata": {
        "id": "fgpiQ0hDwvGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj.get_stoi()[\"two\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve5_5mLbwuQT",
        "outputId": "3514bfeb-3840-4932-86fb-18b1b09e0040"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_vocab), len(de_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9OF9ssSxaPa",
        "outputId": "0354bea7-2517-4c27-eace-a4cd32ed2116"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5893, 7853)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"The\" in en_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PpAp_v-xkwV",
        "outputId": "ff407044-55ab-4ad7-c508-947cfa051897"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert en_vocab_obj[unk_token] == de_vocab_obj[unk_token]\n",
        "assert en_vocab_obj[pad_token] == de_vocab_obj[pad_token]\n",
        "\n",
        "unk_index = en_vocab_obj[unk_token]\n",
        "pad_index =  en_vocab_obj[pad_token]"
      ],
      "metadata": {
        "id": "8mPcoiLKyq6v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj[\"The\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqmecGBpwj8-",
        "outputId": "cda65c5e-89b1-41c3-b469-d90c9c283c4e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj.get_itos()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bZWRO7dqwm8G",
        "outputId": "37364efa-0215-4426-cd77-65390da7875f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]"
      ],
      "metadata": {
        "id": "Et-eRkOdyRtk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj.lookup_indices(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPydldNnAdS3",
        "outputId": "cf0ed44c-ab70-4bd6-9431-32b01156fed5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[171, 4010, 225, 0, 1130]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj.lookup_tokens(en_vocab_obj.lookup_indices(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3tVLnEZxeHP",
        "outputId": "b5b56eb5-600e-4b20-ed5c-280a3a899e31"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'watching', '<unk>', 'shows']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting tokens to indices of our *tokens*"
      ],
      "metadata": {
        "id": "e74TxDtrAtia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numericalize_example(example, en_vocab_obj, de_vocab_obj):\n",
        "  en_ids = en_vocab_obj.lookup_indices(example[\"en_tokens\"])\n",
        "  de_ids = de_vocab_obj.lookup_indices(example[\"de_tokens\"])\n",
        "  return {\"en_ids\": en_ids, \"de_ids\": de_ids }"
      ],
      "metadata": {
        "id": "39drP14Tzk1L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn_kwargs = {\n",
        "    \"en_vocab_obj\": en_vocab_obj,\n",
        "    \"de_vocab_obj\": de_vocab_obj\n",
        "}\n",
        "\n",
        "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
        "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "76df0d79430846948aca376dc9410913",
            "bf9f69c939ba44338bc480ef4289af6d",
            "6b11a04680e84187aa31cd92a3a9a262",
            "9ce8404a40a04646b4a74183225a978c",
            "8c55d9f7be2a43698960278fe86a9a7d",
            "865ff30aef144c60bfd8d1b58dbe0dbf",
            "19597adf05ee4161934bdee08ba32b38",
            "f8a7abe8f22549218720239e80783c52",
            "f5a1a1e2f60e472894b687d3de9627ec",
            "483d31d1573c4f309859d971c602b28d",
            "f40dec40f19c436989c2e38167d923c1",
            "90d6050416a5461eb2a71bccad30a833",
            "6c9359eccb59498196cb38fe68794938",
            "9bd8715b1f8a4d63ab9c47428574c6dd",
            "60471c3bd7644e37898319c0bbd85b94",
            "f41f3674419547eb93482f5731ef4483",
            "1d66ee5abd7d4f2fa327f4579ca8b6ee",
            "f411edaf956847e5940cda70036d8d2b",
            "a92d11a236aa48fabd574e52b4f07d17",
            "80b431bdea9b4ede806ad97fbb0b7fa8",
            "b8437382f665492899aa10432264c336",
            "e10b725d231c47ae990a1453c021d07d",
            "6b3c435b42914851ba6e1d4eb1a584b6",
            "d72b3713f0bd44fb9fc619f458874027",
            "675df68a6ebd4eaa975c694815487eba",
            "41fe635c14c84ad0900d8ac486f77649",
            "433fd92c9deb4c77bc6d1223103a1ec8",
            "69e1e45975124a5682cc363c401ed08e",
            "97dacad9b4614ec999a5a803c3fa893f",
            "5442837388a845f79a61cc484bf98234",
            "52bec18079024c5fb3c4b2af7bb3dce8",
            "db0d3390781a40f39d5f6cbda11eacf2",
            "812a268b926948fa82b562338c9d6f68"
          ]
        },
        "id": "wgpfVaUqz50o",
        "outputId": "bd48f2fa-637a-445d-96a1-183373b21fea"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76df0d79430846948aca376dc9410913"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d6050416a5461eb2a71bccad30a833"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b3c435b42914851ba6e1d4eb1a584b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEBc48eQ0Xj3",
        "outputId": "de46f05f-8161-48d6-d8d4-222ceaed42fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge wei\u00dfe M\u00e4nner sind im Freien in der N\u00e4he vieler B\u00fcsche.',\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'wei\u00dfe',\n",
              "  'm\u00e4nner',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'n\u00e4he',\n",
              "  'vieler',\n",
              "  'b\u00fcsche',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_ids': [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 3],\n",
              " 'de_ids': [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 3]}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_obj.lookup_tokens(train_data[0][\"en_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5XDj0Gr0Zkb",
        "outputId": "2f62d159-a48f-4d98-9dd0-52ab8e8243a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'two',\n",
              " 'young',\n",
              " ',',\n",
              " 'white',\n",
              " 'males',\n",
              " 'are',\n",
              " 'outside',\n",
              " 'near',\n",
              " 'many',\n",
              " 'bushes',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the indices to Pytorch tensors to use in the model"
      ],
      "metadata": {
        "id": "y8L_eynP8YFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_type = \"torch\"\n",
        "format_columns = [\"en_ids\", \"de_ids\"]\n",
        "\n",
        "train_data = train_data.with_format(\n",
        "    type = data_type,\n",
        "    columns = format_columns,\n",
        "    output_all_columns = True\n",
        ")\n",
        "\n",
        "valid_data = valid_data.with_format(\n",
        "    type = data_type,\n",
        "    columns = format_columns,\n",
        "    output_all_columns = True\n",
        ")\n",
        "\n",
        "test_data = test_data.with_format(\n",
        "    type = data_type,\n",
        "    columns = format_columns,\n",
        "    output_all_columns = True\n",
        ")"
      ],
      "metadata": {
        "id": "1gxLUIjU8g-T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n114KYqW9Bia",
        "outputId": "b50ab51a-4382-4718-b8f4-48d3b9d2090f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en_ids': tensor([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  3]),\n",
              " 'de_ids': tensor([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  3]),\n",
              " 'en': 'Two young, White males are outside near many bushes.',\n",
              " 'de': 'Zwei junge wei\u00dfe M\u00e4nner sind im Freien in der N\u00e4he vieler B\u00fcsche.',\n",
              " 'de_tokens': ['<sos>',\n",
              "  'zwei',\n",
              "  'junge',\n",
              "  'wei\u00dfe',\n",
              "  'm\u00e4nner',\n",
              "  'sind',\n",
              "  'im',\n",
              "  'freien',\n",
              "  'in',\n",
              "  'der',\n",
              "  'n\u00e4he',\n",
              "  'vieler',\n",
              "  'b\u00fcsche',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'en_tokens': ['<sos>',\n",
              "  'two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'white',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.',\n",
              "  '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"en_ids_type : \" , type(train_data[0][\"en_ids\"]),\"\\n\"\n",
        "      \"de_ids_type : \", type(train_data[0][\"de_ids\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px9CUKQt9Qe7",
        "outputId": "6327b1de-451b-41a6-ac93-48797f79973b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_ids_type :  <class 'torch.Tensor'> \n",
            "de_ids_type :  <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loaders"
      ],
      "metadata": {
        "id": "AyDe7Y8FGIgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_collate_fn(pad_index):\n",
        "  def collate_fn(batch):\n",
        "    batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
        "    batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
        "    batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
        "    batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
        "    batch = {\n",
        "        \"en_ids\": batch_en_ids,\n",
        "        \"de_ids\": batch_de_ids\n",
        "    }\n",
        "    return batch\n",
        "\n",
        "  return collate_fn"
      ],
      "metadata": {
        "id": "C40Elqsb91EE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "  collate_fn = get_collate_fn(pad_index)\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      collate_fn = collate_fn,\n",
        "      shuffle=shuffle\n",
        "  )\n",
        "\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "mBV7rgBO-75I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
        "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n",
        "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)"
      ],
      "metadata": {
        "id": "lnFVNtv2_jrN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "TzPdHs5lH5L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # src = [src length, batch size]\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    outputs , (hidden, cell) = self.rnn(embedded)\n",
        "    # outputs are always from top hidden layer\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "a5UliOoX_4lz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "    self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    input = input.unsqueeze(0)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "    prediction = self.fc_out(output.squeeze(0))\n",
        "    return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "jrIqcDHoCn4a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    assert (\n",
        "        encoder.hidden_dim == decoder.hidden_dim\n",
        "    ), \"Hidden dimensions of encoder and decoder must be equal.\"\n",
        "    assert (\n",
        "        encoder.n_layers == decoder.n_layers\n",
        "    ), \"Encoder and decoder must have equal number of layers.\"\n",
        "\n",
        "  def forward(self, src, trg, teacher_forcing_ratio):\n",
        "    # teacher forcing ratio is probability of using teacher forcing\n",
        "    batch_size = trg.shape[1]\n",
        "    trg_length = trg.shape[0]\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "    outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
        "    hidden, cell = self.encoder(src)\n",
        "    input = trg[0, :]\n",
        "    for t in range(1, trg_length):\n",
        "      output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "      # placing the predictions in a tensor holding predictions for each token\n",
        "      outputs[t] = output\n",
        "      # if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      # get the highest predicted token from our predictions\n",
        "      top1 = output.argmax(1)\n",
        "      # if teacher forcing, use actual next token as next input\n",
        "      # if not, use predicted token\n",
        "      input = trg[t] if teacher_force else top1\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "LJNln5cREy0-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "T78nVrgbIEVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(de_vocab_obj)\n",
        "output_dim = len(en_vocab_obj)\n",
        "encoder_embedding_dim = 256\n",
        "decoder_embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim,\n",
        "    encoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    encoder_dropout\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    decoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    decoder_dropout\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)"
      ],
      "metadata": {
        "id": "T5jB1SD7DVOh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "4VB-JMreG4G-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704a0977-c57c-4f15-cf4f-a5592c240e84"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ],
      "metadata": {
        "id": "6BmdtWg6HWmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e01746b-340f-48cc-ec8a-d55fd0aafe12"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 13,898,501 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "mKoGHew4LALp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "puK5iJcgHlse"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "gSC2smVmLGd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
      ],
      "metadata": {
        "id": "uxR2_c6pHok1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "xKGyc9VLLRzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(\n",
        "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
        "):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for i, batch in enumerate(data_loader):\n",
        "    src = batch[\"de_ids\"].to(device)\n",
        "    trg = batch[\"en_ids\"].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src, trg, teacher_forcing_ratio)\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output[1:].view(-1, output_dim)\n",
        "    trg = trg[1:].view(-1)\n",
        "    loss = criterion(output, trg)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "NtuWmU7VHwuN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Loop"
      ],
      "metadata": {
        "id": "HAFEX5cQNQCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fn(model, data_loader, criterion, device):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(data_loader):\n",
        "      src = batch[\"de_ids\"].to(device)\n",
        "      trg = batch[\"en_ids\"].to(device)\n",
        "      output = model(src, trg, 0)\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output[1:].view(-1, output_dim)\n",
        "      trg = trg[1:].view(-1)\n",
        "      loss = criterion(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "0HuKdYv0ItZG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "wPpTxXjYNtq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 0.5\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm.tqdm(range(n_epochs)):\n",
        "  train_loss = train_fn(\n",
        "      model,\n",
        "      train_data_loader,\n",
        "      optimizer,\n",
        "      criterion,\n",
        "      clip,\n",
        "      teacher_forcing_ratio,\n",
        "      device\n",
        "  )\n",
        "\n",
        "  valid_loss = evaluate_fn(\n",
        "      model,\n",
        "      valid_data_loader,\n",
        "      criterion,\n",
        "      device\n",
        "  )\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), \"tut3-model.pt\")\n",
        "  print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "  print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
      ],
      "metadata": {
        "id": "_oQnJlRvJRMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d6643e-97d5-4420-dcce-c85ef0c2b398"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|\u2588         | 1/10 [00:46<07:00, 46.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   5.028 | Train PPL: 152.603\n",
            "\tValid Loss:   4.873 | Valid PPL: 130.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|\u2588\u2588        | 2/10 [01:32<06:09, 46.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   4.390 | Train PPL:  80.607\n",
            "\tValid Loss:   4.656 | Valid PPL: 105.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|\u2588\u2588\u2588       | 3/10 [02:18<05:22, 46.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   4.103 | Train PPL:  60.538\n",
            "\tValid Loss:   4.510 | Valid PPL:  90.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [03:04<04:36, 46.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.901 | Train PPL:  49.442\n",
            "\tValid Loss:   4.328 | Valid PPL:  75.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [03:50<03:49, 45.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.714 | Train PPL:  41.005\n",
            "\tValid Loss:   4.244 | Valid PPL:  69.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [04:36<03:03, 45.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.557 | Train PPL:  35.047\n",
            "\tValid Loss:   4.124 | Valid PPL:  61.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [05:21<02:17, 45.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.431 | Train PPL:  30.920\n",
            "\tValid Loss:   4.084 | Valid PPL:  59.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [06:07<01:31, 45.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.297 | Train PPL:  27.040\n",
            "\tValid Loss:   4.050 | Valid PPL:  57.412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [06:53<00:45, 45.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.166 | Train PPL:  23.702\n",
            "\tValid Loss:   3.950 | Valid PPL:  51.953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [07:39<00:00, 45.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.048 | Train PPL:  21.064\n",
            "\tValid Loss:   3.867 | Valid PPL:  47.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"tut3-model.pt\"))\n",
        "\n",
        "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
        "\n",
        "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f}\")"
      ],
      "metadata": {
        "id": "3-UNDSsFfhC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d25fee-235a-40da-b711-8a0a1520843d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.846 | Test PPL:  46.804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(\n",
        "    sentence,\n",
        "    model,\n",
        "    en_nlp,\n",
        "    de_nlp,\n",
        "    en_vocab_obj,\n",
        "    de_vocab_obj,\n",
        "    lower,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "    device,\n",
        "    max_output_length = 25\n",
        "):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    if isinstance(sentence, str):\n",
        "      tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
        "    else:\n",
        "      tokens = [token for token in sentence]\n",
        "    if lower:\n",
        "      tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    tokens = [sos_token] + tokens + [eos_token]\n",
        "    ids = de_vocab_obj.lookup_indices(tokens)\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
        "    hidden, cell = model.encoder(tensor)\n",
        "    inputs = en_vocab_obj.lookup_indices([sos_token])\n",
        "    for _ in range(max_output_length):\n",
        "      inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
        "      output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
        "      predicted_token = output.argmax(-1).item()\n",
        "      inputs.append(predicted_token)\n",
        "      if predicted_token == en_vocab_obj[eos_token]:\n",
        "        break\n",
        "    tokens = en_vocab_obj.lookup_tokens(inputs)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "2uCgIGgdFif8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = test_data[0][\"de\"]\n",
        "expected_translation = test_data[0][\"en\"]\n",
        "\n",
        "sentence, expected_translation"
      ],
      "metadata": {
        "id": "MTBAXuZcS6L-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d5218a-32b8-4fbe-cd26-a299459482de"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
              " 'A man in an orange hat starring at something.')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate_sentence(\n",
        "    sentence,\n",
        "    model,\n",
        "    en_nlp,\n",
        "    de_nlp,\n",
        "    en_vocab_obj,\n",
        "    de_vocab_obj,\n",
        "    lower,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "    device,\n",
        ")"
      ],
      "metadata": {
        "id": "bHzrQKDnTGMp"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "id": "w9-hkbsWTbf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fb627f-1162-41c9-80ab-2f6d3d09e114"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'a',\n",
              " 'man',\n",
              " 'in',\n",
              " 'a',\n",
              " 'black',\n",
              " 'hat',\n",
              " 'is',\n",
              " 'cutting',\n",
              " 'food',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Ein Mann sitzt auf einer Bank.\""
      ],
      "metadata": {
        "id": "tUu0lQD5RFea"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(de_vocab_obj.lookup_indices([\"ein\", \",ann\", \"sitzt\", \"auf\", \"einer\", \"bank\", \".\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok_-E9dBgsM_",
        "outputId": "f68f2d4f-54ef-42cd-f79d-fbe295150908"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21, 0, 110, 33, 34, 115, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate_sentence(\n",
        "    sentence,\n",
        "    model,\n",
        "    en_nlp,\n",
        "    de_nlp,\n",
        "    en_vocab_obj,\n",
        "    de_vocab_obj,\n",
        "    lower,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "    device\n",
        ")"
      ],
      "metadata": {
        "id": "SUQj3fBqRMhs"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4ADueT1Rbzl",
        "outputId": "1be85748-57fd-4c6d-9003-773f8abad02e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'a', 'man', 'sitting', 'on', 'a', 'bench', '.', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translations = [\n",
        "    translate_sentence(\n",
        "        example[\"de\"],\n",
        "        model,\n",
        "        en_nlp,\n",
        "        de_nlp,\n",
        "        en_vocab_obj,\n",
        "        de_vocab_obj,\n",
        "        lower,\n",
        "        sos_token,\n",
        "        eos_token,\n",
        "        device\n",
        "    )\n",
        "    for example in tqdm.tqdm(test_data)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE55fuLhGHnr",
        "outputId": "ad22ddc9-9c87-43e9-ec4d-1fb70b766f51"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:08<00:00, 113.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "id": "kkSZvKHCGTMB"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
        "references = [[example[\"en\"]] for example in test_data]"
      ],
      "metadata": {
        "id": "JkxpfDoRGZQV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0], references[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCsOgGJWGsgY",
        "outputId": "d2a746e7-b492-4ea7-b147-d942b54511b4"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('a man in a black hat is cutting food .',\n",
              " ['A man in an orange hat starring at something.'])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer_fn(nlp, lower):\n",
        "  def tokenizer_fn(s):\n",
        "    tokens = [token.text for token in nlp.tokenizer(s)]\n",
        "    if lower:\n",
        "      tokens = [token.lower() for token in tokens]\n",
        "    return tokens\n",
        "  return tokenizer_fn"
      ],
      "metadata": {
        "id": "htQ5zHpeKDD8"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
      ],
      "metadata": {
        "id": "SHYbiJzJLRzl"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_fn(predictions[0]), tokenizer_fn(references[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xI5xS86LXTI",
        "outputId": "5067a86b-e30c-4529-fee4-5938f7e0be13"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['a', 'man', 'in', 'a', 'black', 'hat', 'is', 'cutting', 'food', '.'],\n",
              " ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = bleu.compute(\n",
        "    predictions = predictions,\n",
        "    references = references,\n",
        "    tokenizer = tokenizer_fn\n",
        ")"
      ],
      "metadata": {
        "id": "3kAyv0NzLwK4"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2cj9jXPL4iP",
        "outputId": "eaa29435-a4da-4e9f-f5f9-bb490fc4a0ed"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bleu': 0.1323227862965373,\n",
              " 'precisions': [0.4748099976494555,\n",
              "  0.18660205729830825,\n",
              "  0.08928737340890086,\n",
              "  0.04250742599610775],\n",
              " 'brevity_penalty': 0.9771513870670351,\n",
              " 'length_ratio': 0.9774084852197886,\n",
              " 'translation_length': 12763,\n",
              " 'reference_length': 13058}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    }
  ]
}
